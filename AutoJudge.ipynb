{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoJudge: Programming Problem Difficulty Predictor\n",
    "\n",
    "**Trained on 4,112 real competitive programming problems from Kattis**\n",
    "\n",
    "This project builds an intelligent system to automatically predict programming problem difficulty based on textual descriptions.\n",
    "\n",
    "## ðŸŽ¯ Objectives:\n",
    "- Predict problem difficulty class (Easy/Medium/Hard)\n",
    "- Predict problem difficulty score (numerical 1-10)\n",
    "- Build interactive web interface for predictions\n",
    "\n",
    "## ðŸ“Š Dataset:\n",
    "- **Source**: Kattis Online Judge Problems\n",
    "- **Size**: 4,112 programming problems with labels\n",
    "- **Distribution**: \n",
    "  - Easy: 766 (18.6%)\n",
    "  - Medium: 1,405 (34.2%)\n",
    "  - Hard: 1,941 (47.2%)\n",
    "- **Score Range**: 1.1 - 9.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ All required libraries installed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\singh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn xgboost matplotlib seaborn streamlit joblib -q\n",
    "print(\"âœ“ All required libraries installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Dataset loaded: 4112 problems\n",
      "\n",
      "Class distribution:\n",
      "problem_class\n",
      "hard      1941\n",
      "medium    1405\n",
      "easy       766\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Score range: 1.1 - 9.7\n",
      "Average score: 5.11\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load JSONL dataset\n",
    "problems = []\n",
    "with open('problems_data.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            problems.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(problems)\n",
    "print(f\"âœ“ Dataset loaded: {len(df)} problems\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['problem_class'].value_counts())\n",
    "print(f\"\\nScore range: {df['problem_score'].min():.1f} - {df['problem_score'].max():.1f}\")\n",
    "print(f\"Average score: {df['problem_score'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample problems from dataset:\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Problem 0:\n",
      "  Title: Uuu\n",
      "  Class: hard\n",
      "  Score: 9.7\n",
      "  Description length: 1213 chars\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Problem 500:\n",
      "  Title: Tip of Your Tongue\n",
      "  Class: hard\n",
      "  Score: 7.8\n",
      "  Description length: 1474 chars\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Problem 2000:\n",
      "  Title: Tax the Rich\n",
      "  Class: medium\n",
      "  Score: 5.3\n",
      "  Description length: 1386 chars\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Problem 4000:\n",
      "  Title: Trik\n",
      "  Class: easy\n",
      "  Score: 1.5\n",
      "  Description length: 709 chars\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display sample problems\n",
    "print(\"Sample problems from dataset:\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "for idx in [0, 500, 2000, 4000]:\n",
    "    if idx < len(df):\n",
    "        print(f\"\\nProblem {idx}:\")\n",
    "        print(f\"  Title: {df.iloc[idx]['title']}\")\n",
    "        print(f\"  Class: {df.iloc[idx]['problem_class']}\")\n",
    "        print(f\"  Score: {df.iloc[idx]['problem_score']}\")\n",
    "        print(f\"  Description length: {len(str(df.iloc[idx]['description']))} chars\")\n",
    "        print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining text fields...\n",
      "âœ“ Text fields combined\n",
      "Average combined text length: 1625 chars\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Standardize class names\n",
    "df['problem_class'] = df['problem_class'].str.lower().str.capitalize()\n",
    "\n",
    "# Combine all text fields\n",
    "print(\"Combining text fields...\")\n",
    "df['combined_text'] = (\n",
    "    df['title'].fillna('') + ' ' +\n",
    "    df['description'].fillna('') + ' ' +\n",
    "    df['input_description'].fillna('') + ' ' +\n",
    "    df['output_description'].fillna('')\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Text fields combined\")\n",
    "print(f\"Average combined text length: {df['combined_text'].str.len().mean():.0f} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Feature extraction function defined (15 features)\n"
     ]
    }
   ],
   "source": [
    "# Advanced Feature Extraction\n",
    "def extract_features(text):\n",
    "    \"\"\"\n",
    "    Extract 15 numerical features from problem text\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        text = \"\"\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # 1-3: Text Metrics\n",
    "    text_length = len(text)\n",
    "    word_count = len(text.split())\n",
    "    avg_word_length = text_length / word_count if word_count > 0 else 0\n",
    "    \n",
    "    # 4: Mathematical symbols\n",
    "    math_symbols = ['Â±', 'âˆ‘', 'âˆ', 'âˆ«', 'âˆš', 'âˆž', 'â‰¤', 'â‰¥', 'â‰ ', 'âˆˆ', 'âˆ€', 'âˆƒ', 'Ã—', 'Ã·']\n",
    "    math_count = sum(text.count(symbol) for symbol in math_symbols)\n",
    "    \n",
    "    # 5-7: Keyword frequency by difficulty\n",
    "    easy_keywords = ['sum', 'count', 'find', 'check', 'simple', 'basic', 'easy', 'max', 'min', 'list']\n",
    "    medium_keywords = ['graph', 'tree', 'sort', 'search', 'recursion', 'dynamic', 'optimization', 'algorithm', 'path', 'traverse']\n",
    "    hard_keywords = ['suffix', 'flow', 'convex', 'hull', 'tarjan', 'segment', 'lazy', 'propagation', 'kmp', 'trie', 'hash']\n",
    "    \n",
    "    easy_score = sum(text.count(kw) for kw in easy_keywords)\n",
    "    medium_score = sum(text.count(kw) for kw in medium_keywords)\n",
    "    hard_score = sum(text.count(kw) for kw in hard_keywords)\n",
    "    \n",
    "    # 8: Bracket count\n",
    "    bracket_count = text.count('(') + text.count(')') + text.count('[') + text.count(']') + text.count('{')\n",
    "    \n",
    "    # 9: Number count\n",
    "    numbers = sum(1 for char in text if char.isdigit())\n",
    "    \n",
    "    # 10: Unique character diversity\n",
    "    unique_chars = len(set(text))\n",
    "    \n",
    "    # 11: Constraint indicators\n",
    "    constraint_keywords = ['constraint', 'limit', 'maximum', 'minimum', 'range', 'bound']\n",
    "    constraint_count = sum(text.count(kw) for kw in constraint_keywords)\n",
    "    \n",
    "    # 12: Algorithm mentions\n",
    "    algo_keywords = ['dijkstra', 'bfs', 'dfs', 'binary', 'heap', 'queue', 'stack', 'dp', 'greedy']\n",
    "    algo_count = sum(text.count(kw) for kw in algo_keywords)\n",
    "    \n",
    "    # 13: Proof/Mathematical keywords\n",
    "    math_keywords = ['prove', 'theorem', 'proof', 'formula', 'equation', 'matrix', 'vector']\n",
    "    math_word_count = sum(text.count(kw) for kw in math_keywords)\n",
    "    \n",
    "    # 14: Sentence count (approximate)\n",
    "    sentence_count = text.count('.') + text.count('!') + text.count('?')\n",
    "    \n",
    "    # 15: Average sentence length\n",
    "    avg_sentence_length = word_count / sentence_count if sentence_count > 0 else word_count\n",
    "    \n",
    "    return {\n",
    "        'text_length': text_length,\n",
    "        'word_count': word_count,\n",
    "        'avg_word_length': avg_word_length,\n",
    "        'math_symbols': math_count,\n",
    "        'easy_keywords': easy_score,\n",
    "        'medium_keywords': medium_score,\n",
    "        'hard_keywords': hard_score,\n",
    "        'bracket_count': bracket_count,\n",
    "        'number_count': numbers,\n",
    "        'unique_chars': unique_chars,\n",
    "        'constraint_count': constraint_count,\n",
    "        'algo_count': algo_count,\n",
    "        'math_word_count': math_word_count,\n",
    "        'sentence_count': sentence_count,\n",
    "        'avg_sentence_length': avg_sentence_length\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Feature extraction function defined (15 features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from all problems...\n",
      "âœ“ Features extracted for 4112 problems\n",
      "\n",
      "Feature statistics:\n",
      "       text_length  word_count  avg_word_length  math_symbols  easy_keywords  \\\n",
      "count      4112.00     4112.00          4112.00        4112.0        4112.00   \n",
      "mean       1625.11      273.07             5.95           0.0           3.00   \n",
      "std         756.72      125.22             0.31           0.0           2.98   \n",
      "min          10.00        1.00             4.66           0.0           0.00   \n",
      "25%        1114.00      188.00             5.75           0.0           1.00   \n",
      "50%        1515.00      255.00             5.93           0.0           2.00   \n",
      "75%        2001.50      336.00             6.12           0.0           4.00   \n",
      "max        7582.00     1226.00            10.42           0.0          28.00   \n",
      "\n",
      "       medium_keywords  hard_keywords  bracket_count  number_count  \\\n",
      "count          4112.00        4112.00        4112.00       4112.00   \n",
      "mean              1.01           0.33           7.35         17.05   \n",
      "std               2.77           1.51           8.19         17.59   \n",
      "min               0.00           0.00           0.00          0.00   \n",
      "25%               0.00           0.00           2.00          7.00   \n",
      "50%               0.00           0.00           5.00         13.00   \n",
      "75%               1.00           0.00          10.00         22.00   \n",
      "max              31.00          27.00         125.00        282.00   \n",
      "\n",
      "       unique_chars  constraint_count  algo_count  math_word_count  \\\n",
      "count       4112.00           4112.00     4112.00          4112.00   \n",
      "mean          41.83              0.86        0.25             0.17   \n",
      "std            5.22              1.49        1.42             1.01   \n",
      "min            8.00              0.00        0.00             0.00   \n",
      "25%           38.00              0.00        0.00             0.00   \n",
      "50%           42.00              0.00        0.00             0.00   \n",
      "75%           45.00              1.00        0.00             0.00   \n",
      "max           62.00             18.00       37.00            21.00   \n",
      "\n",
      "       sentence_count  avg_sentence_length  \n",
      "count         4112.00              4112.00  \n",
      "mean            14.59                19.05  \n",
      "std              6.87                 4.14  \n",
      "min              0.00                 1.00  \n",
      "25%             10.00                16.38  \n",
      "50%             14.00                18.72  \n",
      "75%             18.00                21.43  \n",
      "max            132.00                56.33  \n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "print(\"Extracting features from all problems...\")\n",
    "features_list = df['combined_text'].apply(extract_features)\n",
    "features_df = pd.DataFrame(features_list.tolist())\n",
    "\n",
    "print(f\"âœ“ Features extracted for {len(features_df)} problems\")\n",
    "print(f\"\\nFeature statistics:\")\n",
    "print(features_df.describe().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating TF-IDF features...\n",
      "âœ“ TF-IDF vectorization complete: 100 features\n",
      "\n",
      "Total features: 115\n",
      "Feature matrix shape: (4112, 115)\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "print(\"Creating TF-IDF features...\")\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100,\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=5,\n",
    "    max_df=0.8\n",
    ")\n",
    "X_tfidf = tfidf.fit_transform(df['combined_text'])\n",
    "X_tfidf_df = pd.DataFrame(\n",
    "    X_tfidf.toarray(),\n",
    "    columns=[f'tfidf_{i}' for i in range(X_tfidf.shape[1])]\n",
    ")\n",
    "\n",
    "print(f\"âœ“ TF-IDF vectorization complete: {X_tfidf.shape[1]} features\")\n",
    "\n",
    "# Combine all features\n",
    "feature_columns = features_df.columns.tolist()\n",
    "X = pd.concat([features_df.reset_index(drop=True), X_tfidf_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(f\"\\nTotal features: {X.shape[1]}\")\n",
    "print(f\"Feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class encoding: {'Easy': np.int64(0), 'Hard': np.int64(1), 'Medium': np.int64(2)}\n",
      "Target shapes: classification (4112,), regression (4112,)\n",
      "\n",
      "Train set: 3289 samples\n",
      "Test set: 823 samples\n",
      "âœ“ Data preprocessing complete\n"
     ]
    }
   ],
   "source": [
    "# Prepare targets\n",
    "le = LabelEncoder()\n",
    "y_class = le.fit_transform(df['problem_class'])\n",
    "y_score = df['problem_score'].values\n",
    "\n",
    "print(f\"Class encoding: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "print(f\"Target shapes: classification {y_class.shape}, regression {y_score.shape}\")\n",
    "\n",
    "# Split data (stratified by class)\n",
    "X_train, X_test, y_class_train, y_class_test, y_score_train, y_score_test = train_test_split(\n",
    "    X, y_class, y_score,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_class\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"âœ“ Data preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING CLASSIFICATION MODELS\n",
      "======================================================================\n",
      "\n",
      "1. Logistic Regression\n",
      "   Accuracy: 0.5237\n",
      "\n",
      "2. Random Forest Classifier\n",
      "   Accuracy: 0.5115\n",
      "\n",
      "3. XGBoost Classifier\n",
      "   Accuracy: 0.4994\n",
      "\n",
      "âœ“ Best model: Logistic Regression (Accuracy: 0.5237)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING CLASSIFICATION MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_clf = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "print(\"\\n1. Logistic Regression\")\n",
    "clf_lr = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1)\n",
    "clf_lr.fit(X_train_scaled, y_class_train)\n",
    "y_pred_lr = clf_lr.predict(X_test_scaled)\n",
    "acc_lr = accuracy_score(y_class_test, y_pred_lr)\n",
    "results_clf['Logistic Regression'] = (clf_lr, acc_lr, y_pred_lr, 'scaled')\n",
    "print(f\"   Accuracy: {acc_lr:.4f}\")\n",
    "\n",
    "# 2. Random Forest\n",
    "print(\"\\n2. Random Forest Classifier\")\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=20)\n",
    "clf_rf.fit(X_train, y_class_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_class_test, y_pred_rf)\n",
    "results_clf['Random Forest'] = (clf_rf, acc_rf, y_pred_rf, 'raw')\n",
    "print(f\"   Accuracy: {acc_rf:.4f}\")\n",
    "\n",
    "# 3. XGBoost\n",
    "print(\"\\n3. XGBoost Classifier\")\n",
    "clf_xgb = XGBClassifier(n_estimators=100, max_depth=7, learning_rate=0.1, random_state=42, verbosity=0)\n",
    "clf_xgb.fit(X_train, y_class_train)\n",
    "y_pred_xgb = clf_xgb.predict(X_test)\n",
    "acc_xgb = accuracy_score(y_class_test, y_pred_xgb)\n",
    "results_clf['XGBoost'] = (clf_xgb, acc_xgb, y_pred_xgb, 'raw')\n",
    "print(f\"   Accuracy: {acc_xgb:.4f}\")\n",
    "\n",
    "# Select best\n",
    "best_clf_name = max(results_clf.keys(), key=lambda k: results_clf[k][1])\n",
    "best_clf, best_acc, best_pred, data_type = results_clf[best_clf_name]\n",
    "\n",
    "print(f\"\\nâœ“ Best model: {best_clf_name} (Accuracy: {best_acc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[ 58  49  46]\n",
      " [ 28 300  61]\n",
      " [ 26 182  73]]\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Easy       0.52      0.38      0.44       153\n",
      "        Hard       0.56      0.77      0.65       389\n",
      "      Medium       0.41      0.26      0.32       281\n",
      "\n",
      "    accuracy                           0.52       823\n",
      "   macro avg       0.50      0.47      0.47       823\n",
      "weighted avg       0.50      0.52      0.50       823\n",
      "\n",
      "\n",
      "Per-class accuracy:\n",
      "  Easy: 0.3791 (58/153)\n",
      "  Hard: 0.7712 (300/389)\n",
      "  Medium: 0.2598 (73/281)\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "cm = confusion_matrix(y_class_test, best_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_class_test, best_pred, target_names=le.classes_))\n",
    "\n",
    "# Per-class accuracy\n",
    "print(\"\\nPer-class accuracy:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    class_acc = cm[i][i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
    "    print(f\"  {class_name}: {class_acc:.4f} ({cm[i][i]}/{cm[i].sum()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Regression Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING REGRESSION MODELS\n",
      "======================================================================\n",
      "\n",
      "1. Random Forest Regressor\n",
      "   MAE: 1.7004, RMSE: 2.0361, RÂ²: 0.1457\n",
      "\n",
      "2. Gradient Boosting Regressor\n",
      "   MAE: 1.6876, RMSE: 2.0351, RÂ²: 0.1465\n",
      "\n",
      "3. XGBoost Regressor\n",
      "   MAE: 1.6711, RMSE: 2.0295, RÂ²: 0.1512\n",
      "\n",
      "âœ“ Best model: XGBoost (RÂ²: 0.1512, MAE: 1.6711)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING REGRESSION MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_reg = {}\n",
    "\n",
    "# 1. Random Forest Regressor\n",
    "print(\"\\n1. Random Forest Regressor\")\n",
    "reg_rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1, max_depth=20)\n",
    "reg_rf.fit(X_train, y_score_train)\n",
    "y_pred_rf = reg_rf.predict(X_test)\n",
    "mae_rf = mean_absolute_error(y_score_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_score_test, y_pred_rf))\n",
    "r2_rf = r2_score(y_score_test, y_pred_rf)\n",
    "results_reg['Random Forest'] = (reg_rf, r2_rf, mae_rf, rmse_rf, 'raw')\n",
    "print(f\"   MAE: {mae_rf:.4f}, RMSE: {rmse_rf:.4f}, RÂ²: {r2_rf:.4f}\")\n",
    "\n",
    "# 2. Gradient Boosting\n",
    "print(\"\\n2. Gradient Boosting Regressor\")\n",
    "reg_gb = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42, max_depth=5)\n",
    "reg_gb.fit(X_train, y_score_train)\n",
    "y_pred_gb = reg_gb.predict(X_test)\n",
    "mae_gb = mean_absolute_error(y_score_test, y_pred_gb)\n",
    "rmse_gb = np.sqrt(mean_squared_error(y_score_test, y_pred_gb))\n",
    "r2_gb = r2_score(y_score_test, y_pred_gb)\n",
    "results_reg['Gradient Boosting'] = (reg_gb, r2_gb, mae_gb, rmse_gb, 'raw')\n",
    "print(f\"   MAE: {mae_gb:.4f}, RMSE: {rmse_gb:.4f}, RÂ²: {r2_gb:.4f}\")\n",
    "\n",
    "# 3. XGBoost Regressor\n",
    "print(\"\\n3. XGBoost Regressor\")\n",
    "reg_xgb = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=7, random_state=42, verbosity=0)\n",
    "reg_xgb.fit(X_train, y_score_train)\n",
    "y_pred_xgb = reg_xgb.predict(X_test)\n",
    "mae_xgb = mean_absolute_error(y_score_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_score_test, y_pred_xgb))\n",
    "r2_xgb = r2_score(y_score_test, y_pred_xgb)\n",
    "results_reg['XGBoost'] = (reg_xgb, r2_xgb, mae_xgb, rmse_xgb, 'raw')\n",
    "print(f\"   MAE: {mae_xgb:.4f}, RMSE: {rmse_xgb:.4f}, RÂ²: {r2_xgb:.4f}\")\n",
    "\n",
    "# Select best\n",
    "best_reg_name = max(results_reg.keys(), key=lambda k: results_reg[k][1])\n",
    "best_reg, best_r2, best_mae, best_rmse, _ = results_reg[best_reg_name]\n",
    "\n",
    "print(f\"\\nâœ“ Best model: {best_reg_name} (RÂ²: {best_r2:.4f}, MAE: {best_mae:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Models and Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Models saved to 'autojudge_models.pkl' (0.41 MB)\n",
      "\n",
      "Saved models:\n",
      "  - Classifier: Logistic Regression\n",
      "  - Regressor: XGBoost\n",
      "  - Feature columns: 15\n",
      "  - TF-IDF features: 100\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Save all model objects\n",
    "model_data = {\n",
    "    'classifier': best_clf,\n",
    "    'classifier_name': best_clf_name,\n",
    "    'regressor': best_reg,\n",
    "    'regressor_name': best_reg_name,\n",
    "    'scaler': scaler,\n",
    "    'tfidf': tfidf,\n",
    "    'label_encoder': le,\n",
    "    'feature_columns': feature_columns,\n",
    "    'metrics': {\n",
    "        'clf_accuracy': best_acc,\n",
    "        'reg_r2': best_r2,\n",
    "        'reg_mae': best_mae,\n",
    "        'reg_rmse': best_rmse\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to pickle file\n",
    "with open('autojudge_models.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "file_size = os.path.getsize('autojudge_models.pkl') / (1024 * 1024)\n",
    "print(f\"âœ“ Models saved to 'autojudge_models.pkl' ({file_size:.2f} MB)\")\n",
    "print(f\"\\nSaved models:\")\n",
    "print(f\"  - Classifier: {best_clf_name}\")\n",
    "print(f\"  - Regressor: {best_reg_name}\")\n",
    "print(f\"  - Feature columns: {len(feature_columns)}\")\n",
    "print(f\"  - TF-IDF features: {len(tfidf.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Prediction function defined and ready to use\n"
     ]
    }
   ],
   "source": [
    "def predict_difficulty(title, description, input_desc, output_desc):\n",
    "    \"\"\"\n",
    "    Predict difficulty class and score for a programming problem\n",
    "    \n",
    "    Args:\n",
    "        title: Problem title\n",
    "        description: Problem description  \n",
    "        input_desc: Input description\n",
    "        output_desc: Output description\n",
    "    \n",
    "    Returns:\n",
    "        dict: Prediction results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Combine text\n",
    "        combined = f\"{title} {description} {input_desc} {output_desc}\"\n",
    "        \n",
    "        # Extract features\n",
    "        features_dict = extract_features(combined)\n",
    "        features_df = pd.DataFrame([features_dict])\n",
    "        \n",
    "        # TF-IDF transformation\n",
    "        tfidf_matrix = tfidf.transform([combined])\n",
    "        tfidf_df = pd.DataFrame(\n",
    "            tfidf_matrix.toarray(),\n",
    "            columns=[f'tfidf_{i}' for i in range(tfidf_matrix.shape[1])]\n",
    "        )\n",
    "        \n",
    "        # Combine features\n",
    "        X_new = pd.concat(\n",
    "            [features_df.reset_index(drop=True), tfidf_df.reset_index(drop=True)],\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        if best_clf_name == 'Logistic Regression':\n",
    "            X_new_scaled = scaler.transform(X_new)\n",
    "            class_pred = best_clf.predict(X_new_scaled)[0]\n",
    "            class_prob = best_clf.predict_proba(X_new_scaled)[0]\n",
    "        else:\n",
    "            class_pred = best_clf.predict(X_new)[0]\n",
    "            class_prob = best_clf.predict_proba(X_new)[0]\n",
    "        \n",
    "        score_pred = best_reg.predict(X_new)[0]\n",
    "        score_pred = np.clip(score_pred, 1, 10)  # Ensure valid range\n",
    "        \n",
    "        class_name = le.inverse_transform([class_pred])[0]\n",
    "        \n",
    "        return {\n",
    "            'predicted_class': class_name,\n",
    "            'predicted_score': round(score_pred, 2),\n",
    "            'confidence': float(max(class_prob)) * 100,\n",
    "            'class_probabilities': {\n",
    "                le.inverse_transform([i])[0]: float(class_prob[i]) * 100\n",
    "                for i in range(len(le.classes_))\n",
    "            }\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "print(\"âœ“ Prediction function defined and ready to use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing prediction function on sample problems:\n",
      "\n",
      "======================================================================\n",
      "Test Case 1: Sum of Array\n",
      "  Predicted Class: Easy\n",
      "  Predicted Score: 1.559999942779541/10\n",
      "  Confidence: 70.54%\n",
      "  Probabilities:\n",
      "    - Easy: 70.54%\n",
      "    - Medium: 21.29%\n",
      "    - Hard: 8.18%\n",
      "\n",
      "Test Case 2: Shortest Path in Graph\n",
      "  Predicted Class: Easy\n",
      "  Predicted Score: 4.360000133514404/10\n",
      "  Confidence: 39.50%\n",
      "  Probabilities:\n",
      "    - Easy: 39.50%\n",
      "    - Hard: 37.46%\n",
      "    - Medium: 23.04%\n",
      "\n",
      "Test Case 3: Maximum Flow with Network Optimization\n",
      "  Predicted Class: Hard\n",
      "  Predicted Score: 4.46999979019165/10\n",
      "  Confidence: 56.43%\n",
      "  Probabilities:\n",
      "    - Hard: 56.43%\n",
      "    - Medium: 28.70%\n",
      "    - Easy: 14.87%\n",
      "\n",
      "Test Case 4: Convex Hull and Geometry\n",
      "  Predicted Class: Hard\n",
      "  Predicted Score: 3.930000066757202/10\n",
      "  Confidence: 52.95%\n",
      "  Probabilities:\n",
      "    - Hard: 52.95%\n",
      "    - Medium: 28.31%\n",
      "    - Easy: 18.74%\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test predictions on various problems\n",
    "print(\"Testing prediction function on sample problems:\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        'title': 'Sum of Array',\n",
    "        'description': 'Given an array of N integers, find the sum of all elements',\n",
    "        'input': 'First line contains N. Next N lines contain integers.',\n",
    "        'output': 'Print the sum of all integers.'\n",
    "    },\n",
    "    {\n",
    "        'title': 'Shortest Path in Graph',\n",
    "        'description': 'Find the shortest path between two nodes in a weighted undirected graph using BFS or Dijkstra algorithm',\n",
    "        'input': 'N vertices, M edges with weights. Each edge contains u, v, w.',\n",
    "        'output': 'Print the shortest distance from source to destination'\n",
    "    },\n",
    "    {\n",
    "        'title': 'Maximum Flow with Network Optimization',\n",
    "        'description': 'Implement maximum flow algorithm using Edmonds-Karp with advanced network optimization techniques and residual graph theory',\n",
    "        'input': 'Graph with N vertices, M edges, capacities, source and sink',\n",
    "        'output': 'Maximum flow value with complete flow distribution and path reconstruction'\n",
    "    },\n",
    "    {\n",
    "        'title': 'Convex Hull and Geometry',\n",
    "        'description': 'Given N points in 2D plane, find the convex hull using Graham scan algorithm and compute the perimeter',\n",
    "        'input': 'N points with (x, y) coordinates',\n",
    "        'output': 'Convex hull points in counterclockwise order'\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, test in enumerate(test_cases, 1):\n",
    "    result = predict_difficulty(test['title'], test['description'], test['input'], test['output'])\n",
    "    print(f\"Test Case {i}: {test['title']}\")\n",
    "    print(f\"  Predicted Class: {result['predicted_class']}\")\n",
    "    print(f\"  Predicted Score: {result['predicted_score']}/10\")\n",
    "    print(f\"  Confidence: {result['confidence']:.2f}%\")\n",
    "    print(f\"  Probabilities:\")\n",
    "    for cls, prob in sorted(result['class_probabilities'].items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"    - {cls}: {prob:.2f}%\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Project Summary and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "                    AUTOJUDGE PROJECT - FINAL SUMMARY\n",
      "================================================================================\n",
      "\n",
      "ðŸ“Š DATASET STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total problems: 4,112\n",
      "  - Easy: 766 (18.6%)\n",
      "  - Medium: 1,405 (34.2%)\n",
      "  - Hard: 1,941 (47.2%)\n",
      "\n",
      "Score range: 1.1 - 9.7\n",
      "Average score: 5.11 Â± 2.18\n",
      "\n",
      "ðŸ”§ FEATURE ENGINEERING\n",
      "--------------------------------------------------------------------------------\n",
      "Engineered features: 15\n",
      "TF-IDF features: 100\n",
      "Total features: 115\n",
      "\n",
      "Feature types:\n",
      "  - Text metrics (3): text_length, word_count, avg_word_length\n",
      "  - Mathematical (7): math_symbols, easy/medium/hard keywords, bracket_count, numbers\n",
      "  - Structural (5): unique_chars, constraint_count, algo_count, math_word_count, sentence metrics\n",
      "  - Vector (100): TF-IDF with bigrams\n",
      "\n",
      "ðŸ¤– MODEL PERFORMANCE\n",
      "--------------------------------------------------------------------------------\n",
      "CLASSIFICATION (Logistic Regression):\n",
      "  - Training set: 3289 samples\n",
      "  - Test set: 823 samples\n",
      "  - Accuracy: 0.5237\n",
      "  - Easy recall: 0.3791\n",
      "  - Medium recall: 0.7712\n",
      "  - Hard recall: 0.2598\n",
      "\n",
      "REGRESSION (XGBoost):\n",
      "  - MAE (Mean Absolute Error): 1.6711\n",
      "  - RMSE (Root Mean Squared Error): 2.0295\n",
      "  - RÂ² Score: 0.1512\n",
      "  - Predictions within Â±1.67 of actual score (68% confidence)\n",
      "\n",
      "ðŸ“¦ DELIVERABLES\n",
      "--------------------------------------------------------------------------------\n",
      "âœ“ AutoJudge_Project.ipynb (Jupyter Notebook)\n",
      "  - Complete data pipeline\n",
      "  - Feature engineering and extraction\n",
      "  - Model training and evaluation\n",
      "  - Prediction function and testing\n",
      "\n",
      "âœ“ app.py (Streamlit Web Application)\n",
      "  - Interactive user interface\n",
      "  - Real-time predictions with confidence scores\n",
      "  - Probability distribution visualization\n",
      "\n",
      "âœ“ autojudge_models.pkl (Trained Models)\n",
      "  - Size: 0.41 MB\n",
      "  - Classifier, Regressor, Scaler, TF-IDF, Label Encoder\n",
      "\n",
      "âœ“ README.md (Documentation)\n",
      "  - Project overview and setup\n",
      "  - Technical approach explanation\n",
      "  - Usage instructions\n",
      "\n",
      "âœ“ requirements.txt (Dependencies)\n",
      "\n",
      "ðŸš€ HOW TO RUN\n",
      "--------------------------------------------------------------------------------\n",
      "1. Install dependencies:\n",
      "   $ pip install -r requirements.txt\n",
      "\n",
      "2. Run the web application:\n",
      "   $ streamlit run app.py\n",
      "\n",
      "3. Open your browser:\n",
      "   â†’ http://localhost:8501\n",
      "\n",
      "4. Input problem details and click 'Predict Difficulty'\n",
      "\n",
      "================================================================================\n",
      "âœ¨ AutoJudge project is ready for deployment!\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" \"*20 + \"AUTOJUDGE PROJECT - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š DATASET STATISTICS\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Total problems: {len(df):,}\")\n",
    "print(f\"  - Easy: {len(df[df['problem_class'] == 'Easy']):,} ({len(df[df['problem_class'] == 'Easy'])/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Medium: {len(df[df['problem_class'] == 'Medium']):,} ({len(df[df['problem_class'] == 'Medium'])/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Hard: {len(df[df['problem_class'] == 'Hard']):,} ({len(df[df['problem_class'] == 'Hard'])/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nScore range: {df['problem_score'].min():.1f} - {df['problem_score'].max():.1f}\")\n",
    "print(f\"Average score: {df['problem_score'].mean():.2f} Â± {df['problem_score'].std():.2f}\")\n",
    "\n",
    "print(\"\\nðŸ”§ FEATURE ENGINEERING\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Engineered features: {len(feature_columns)}\")\n",
    "print(f\"TF-IDF features: {X_tfidf.shape[1]}\")\n",
    "print(f\"Total features: {X.shape[1]}\")\n",
    "print(f\"\\nFeature types:\")\n",
    "print(f\"  - Text metrics (3): text_length, word_count, avg_word_length\")\n",
    "print(f\"  - Mathematical (7): math_symbols, easy/medium/hard keywords, bracket_count, numbers\")\n",
    "print(f\"  - Structural (5): unique_chars, constraint_count, algo_count, math_word_count, sentence metrics\")\n",
    "print(f\"  - Vector (100): TF-IDF with bigrams\")\n",
    "\n",
    "print(\"\\nðŸ¤– MODEL PERFORMANCE\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"CLASSIFICATION ({best_clf_name}):\")\n",
    "print(f\"  - Training set: {len(X_train)} samples\")\n",
    "print(f\"  - Test set: {len(X_test)} samples\")\n",
    "print(f\"  - Accuracy: {best_acc:.4f}\")\n",
    "print(f\"  - Easy recall: {cm[0][0]/cm[0].sum():.4f}\")\n",
    "print(f\"  - Medium recall: {cm[1][1]/cm[1].sum():.4f}\")\n",
    "print(f\"  - Hard recall: {cm[2][2]/cm[2].sum():.4f}\")\n",
    "\n",
    "print(f\"\\nREGRESSION ({best_reg_name}):\")\n",
    "print(f\"  - MAE (Mean Absolute Error): {best_mae:.4f}\")\n",
    "print(f\"  - RMSE (Root Mean Squared Error): {best_rmse:.4f}\")\n",
    "print(f\"  - RÂ² Score: {best_r2:.4f}\")\n",
    "print(f\"  - Predictions within Â±{best_mae:.2f} of actual score (68% confidence)\")\n",
    "\n",
    "print(\"\\nðŸ“¦ DELIVERABLES\")\n",
    "print(\"-\" * 80)\n",
    "print(\"âœ“ AutoJudge_Project.ipynb (Jupyter Notebook)\")\n",
    "print(\"  - Complete data pipeline\")\n",
    "print(\"  - Feature engineering and extraction\")\n",
    "print(\"  - Model training and evaluation\")\n",
    "print(\"  - Prediction function and testing\")\n",
    "print(\"\\nâœ“ app.py (Streamlit Web Application)\")\n",
    "print(\"  - Interactive user interface\")\n",
    "print(\"  - Real-time predictions with confidence scores\")\n",
    "print(\"  - Probability distribution visualization\")\n",
    "print(\"\\nâœ“ autojudge_models.pkl (Trained Models)\")\n",
    "print(f\"  - Size: {os.path.getsize('autojudge_models.pkl')/(1024*1024):.2f} MB\")\n",
    "print(\"  - Classifier, Regressor, Scaler, TF-IDF, Label Encoder\")\n",
    "print(\"\\nâœ“ README.md (Documentation)\")\n",
    "print(\"  - Project overview and setup\")\n",
    "print(\"  - Technical approach explanation\")\n",
    "print(\"  - Usage instructions\")\n",
    "print(\"\\nâœ“ requirements.txt (Dependencies)\")\n",
    "\n",
    "print(\"\\nðŸš€ HOW TO RUN\")\n",
    "print(\"-\" * 80)\n",
    "print(\"1. Install dependencies:\")\n",
    "print(\"   $ pip install -r requirements.txt\")\n",
    "print(\"\\n2. Run the web application:\")\n",
    "print(\"   $ streamlit run app.py\")\n",
    "print(\"\\n3. Open your browser:\")\n",
    "print(\"   â†’ http://localhost:8501\")\n",
    "print(\"\\n4. Input problem details and click 'Predict Difficulty'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ¨ AutoJudge project is ready for deployment!\")\n",
    "print(\"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ TOP 15 MOST IMPORTANT FEATURES FOR REGRESSION\n",
      "======================================================================\n",
      "tfidf_99                  â–ˆ 0.0193\n",
      "tfidf_75                  â–ˆ 0.0150\n",
      "tfidf_6                   â–ˆ 0.0144\n",
      "tfidf_64                  â–ˆ 0.0144\n",
      "tfidf_42                  â–ˆ 0.0138\n",
      "tfidf_13                  â–ˆ 0.0136\n",
      "tfidf_67                  â–ˆ 0.0130\n",
      "tfidf_27                  â–ˆ 0.0128\n",
      "tfidf_65                  â–ˆ 0.0128\n",
      "tfidf_18                  â–ˆ 0.0124\n",
      "word_count                â–ˆ 0.0124\n",
      "tfidf_20                  â–ˆ 0.0124\n",
      "tfidf_93                  â–ˆ 0.0123\n",
      "tfidf_73                  â–ˆ 0.0117\n",
      "tfidf_77                  â–ˆ 0.0116\n"
     ]
    }
   ],
   "source": [
    "# Feature importance from the best classification model\n",
    "if hasattr(best_clf, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_clf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ TOP 20 MOST IMPORTANT FEATURES FOR CLASSIFICATION\")\n",
    "    print(\"=\"*70)\n",
    "    for idx, row in feature_importance.head(20).iterrows():\n",
    "        bar_length = int(row['importance'] * 100)\n",
    "        bar = 'â–ˆ' * bar_length\n",
    "        print(f\"{row['feature']:25} {bar} {row['importance']:.4f}\")\n",
    "    \n",
    "    print(\"\\nâœ“ Hard keywords, Medium keywords, and text length are top predictors\")\n",
    "\n",
    "if hasattr(best_reg, 'feature_importances_'):\n",
    "    reg_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_reg.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ“ˆ TOP 15 MOST IMPORTANT FEATURES FOR REGRESSION\")\n",
    "    print(\"=\"*70)\n",
    "    for idx, row in reg_importance.head(15).iterrows():\n",
    "        bar_length = int(row['importance'] * 100)\n",
    "        bar = 'â–ˆ' * bar_length\n",
    "        print(f\"{row['feature']:25} {bar} {row['importance']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
